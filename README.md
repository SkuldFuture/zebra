# Структура проекта

```
zebra/
└───REPORT_MD             # Папка с Markdown файлом отчета о проделанной работе 
        output_13_1.png
        output_19_1.png
        output_22_1.png
        output_24_1.png
        output_26_1.png
        output_29_1.png
        output_5_1.png
        output_6_1.png
        output_7_1.png
        output_8_1.png
        REPORT.md
├── train.py                # Скрипт обучения, валидации и экспорта
├───dataset/                # Не включен в .git, хранятся оригинальные видео, нужен только для Jupyter notebook
├── keyframes/              # Кадры из видео для разметки
├── annotations/            # Размеченные данные
├── augmented_dataset/      # Датасет с аугментацией
├── requirements.txt        # Список зависимостей
├── yolo11n.pt              # Базовые веса YOLO
└───runs_zebra_dishes       # Результаты обучения
```


# Как запускать

1. Нужно создать виртуальное окружение и установить все необходимые библиотеки:

   ```bash
   python -m venv .venv
   .\.venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. Опционально: для воспроизведения ячеек Jupyter необходимо поместить оригинальный 
датасет с видео в папку `dataset` и запустить каждую ячейку в хронологическом порядке

2. Запустить обучение:

   ```bash
   python train.py
   ```
   
# Сроки и возникшие сложности

Честно времени ушло около 11 часов в субботу и по паре часов в будни,
потому что было желание играться с методами разбиения видео (датасет 
порой важнее гиперпараметров) и вспомнить теорию. 

Позже обнаружилось, что CVAT при экспорте удалял в случайном порядке 
bounding boxes, которые перекрывали друг друга, из-за этого пришлось
размечать часть дать датасета заново и переучивать модель. В целом,
есть форматы, которые работают с перекрытием, и можно было написать 
скрипт конвертации такого формата в YOLO, но время уже поджимало)``
